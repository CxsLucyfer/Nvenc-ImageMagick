name: Docker Image CI

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:

  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag my-image-name:$(date +%s)
- name: Setup Node.js environment
  uses: actions/setup-node@v3.8.1
  with:
    # Set always-auth in npmrc.
    always-auth: # optional, default is false
    # Version Spec of the version to use. Examples: 12.x, 10.15.1, >=10.15.0.
    node-version: # optional
    # File containing the version Spec of the version to use.  Examples: .nvmrc, .node-version, .tool-versions.
    node-version-file: # optional
    # Target architecture for Node to use. Examples: x86, x64. Will use system architecture by default.
    architecture: # optional
    # Set this option if you want the action to check for the latest available version that satisfies the version spec.
    check-latest: # optional
    # Optional registry to set up for auth. Will set the registry in a project level .npmrc and .yarnrc file, and set up auth to read in from env.NODE_AUTH_TOKEN.
    registry-url: # optional
    # Optional scope for authenticating against scoped registries. Will fall back to the repository owner when using the GitHub Packages registry (https://npm.pkg.github.com/).
    scope: # optional
    # Used to pull node distributions from node-versions. Since there's a default, this is typically not supplied by the user. When running this action on github.com, the default value is sufficient. When running on GHES, you can pass a personal access token for github.com if you are experiencing rate limiting.
    token: # optional, default is ${{ github.server_url == 'https://github.com' && github.token || '' }}
    # Used to specify a package manager for caching in the default directory. Supported values: npm, yarn, pnpm.
    cache: # optional
    # Used to specify the path to a dependency file: package-lock.json, yarn.lock, etc. Supports wildcards or a list of file names for caching multiple dependencies.
    cache-dependency-path: # optional

    - name: Setup Java JDK
  uses: actions/setup-java@v3.12.0
  with:
    # The Java version to set up. Takes a whole or semver Java version. See examples of supported syntax in README file
    java-version: # optional
    # The path to the `.java-version` file. See examples of supported syntax in README file
    java-version-file: # optional
    # Java distribution. See the list of supported distributions in README file
    distribution: 
    # The package type (jdk, jre, jdk+fx, jre+fx)
    java-package: # optional, default is jdk
    # The architecture of the package (defaults to the action runner's architecture)
    architecture: # optional
    # Path to where the compressed JDK is located
    jdkFile: # optional
    # Set this option if you want the action to check for the latest available version that satisfies the version spec
    check-latest: # optional
    # ID of the distributionManagement repository in the pom.xml file. Default is `github`
    server-id: # optional, default is github
    # Environment variable name for the username for authentication to the Apache Maven repository. Default is $GITHUB_ACTOR
    server-username: # optional, default is GITHUB_ACTOR
    # Environment variable name for password or token for authentication to the Apache Maven repository. Default is $GITHUB_TOKEN
    server-password: # optional, default is GITHUB_TOKEN
    # Path to where the settings.xml file will be written. Default is ~/.m2.
    settings-path: # optional
    # Overwrite the settings.xml file if it exists. Default is "true".
    overwrite-settings: # optional, default is true
    # GPG private key to import. Default is empty string.
    gpg-private-key: # optional
    # Environment variable name for the GPG private key passphrase. Default is $GPG_PASSPHRASE.
    gpg-passphrase: # optional
    # Name of the build platform to cache dependencies. It can be "maven", "gradle" or "sbt".
    cache: # optional
    # Workaround to pass job status to post job step. This variable is not intended for manual setting
    job-status: # optional, default is ${{ job.status }}
    # The token used to authenticate when fetching version manifests hosted on github.com, such as for the Microsoft Build of OpenJDK. When running this action on github.com, the default value is sufficient. When running on GHES, you can pass a personal access token for github.com if you are experiencing rate limiting.
    token: # optional, default is ${{ github.server_url == 'https://github.com' && github.token || '' }}
    # Name of Maven Toolchain ID if the default name of "${distribution}_${java-version}" is not wanted. See examples of supported syntax in Advanced Usage file
    mvn-toolchain-id: # optional
    # Name of Maven Toolchain Vendor if the default name of "${distribution}" is not wanted. See examples of supported syntax in Advanced Usage file
    mvn-toolchain-vendor: # optional

   - name: Setup .NET Core SDK
  uses: actions/setup-dotnet@v3.2.0
  with:
    # Optional SDK version(s) to use. If not provided, will install global.json version when available. Examples: 2.2.104, 3.1, 3.1.x, 3.x, 6.0.2xx
    dotnet-version: # optional
    # Optional quality of the build. The possible values are: daily, signed, validated, preview, ga.
    dotnet-quality: # optional
    # Optional global.json location, if your global.json isn't located in the root of the repo.
    global-json-file: # optional
    # Optional package source for which to set up authentication. Will consult any existing NuGet.config in the root of the repo and provide a temporary NuGet.config using the NUGET_AUTH_TOKEN environment variable as a ClearTextPassword
    source-url: # optional
    # Optional OWNER for using packages from GitHub Package Registry organizations/users other than the current repository's owner. Only used if a GPR URL is also provided in source-url
    owner: # optional
    # Optional NuGet.config location, if your NuGet.config isn't located in the root of the repo.
    config-file: # optional
    # Optional input to enable caching of the NuGet global-packages folder
    cache: # optional
    # Used to specify the path to a dependency file: packages.lock.json. Supports wildcards or a list of file names for caching multiple dependencies.
    cache-dependency-path: # optional

   - name: Jira Login
  # You may pin to the exact commit or the version.
  # uses: atlassian/gajira-login@ca13f8850ea309cf44a6e4e0c49d9aa48ac3ca4c
  uses: atlassian/gajira-login@v3

  - name: Repository Visibility SMS Alert
  # You may pin to the exact commit or the version.
  # uses: bitoiu/repo-visibility-alert-action@65533b09ffbebc4ffeb02c8d18034c8f6cc3fb0e
  uses: bitoiu/repo-visibility-alert-action@v0.1


  - name: Visual Studio Marketplace Publisher
  # You may pin to the exact commit or the version.
  # uses: CalvinAllen/action-vs-marketplace-publish@95d0ed2b06b0368f9997925ac8b4b9c27e61f26a
  uses: CalvinAllen/action-vs-marketplace-publish@v1
  with:
    # Your personal access token for the Marketplace
    marketplace-pat: 
    # Relative path to your publish manifest
    publish-manifest-path: 
    # Relative path to your VSIX file
    vsix-path: 
    # Version of Visual Studio to search; defaults to latest if not specified
    vs-version: # optional
    # Enable searching for pre-release versions of Visual Studio
    vs-prerelease: # optional
- name: Repo Visualizer
  # You may pin to the exact commit or the version.
  # uses: githubocto/repo-visualizer@a999615bdab757559bf94bda1fe6eef232765f85
  uses: githubocto/repo-visualizer@0.9.1
  with:
    # A path (relative to the root of your repo) to where you would like the diagram to live. For example: images/diagram.svg. Default: diagram.svg
    output_file: # optional
    # A list of paths to exclude from the diagram, separated by commas. For example: dist,node_modules
    excluded_paths: # optional
    # A list of micromatch globs to exclude from the diagram, separated by semicolons. For example: **/*.png;docs/**/*.{png,ico}
    excluded_globs: # optional
    # The directory (and its children) that you want to visualize in the diagram. Default: "" (repository root directory)
    root_path: # optional
    # The maximum number of nested folders to show files within. Default: 9
    max_depth: # optional
    # The commit message to use when updating the diagram. Default: Repo visualizer: updated diagram
    commit_message: # optional
    # The branch name to push the diagram to (branch will be created if it does not yet exist). For example: diagram
    branch: # optional
    # Whether to push the new commit back to the repository. Must be true or false. Default: true
    should_push: # optional, default is true
    # If given, the name of an artifact to be created containing the diagram. Default: don't create an artifact.
    artifact_name: # optional, default is 
    # You can customize the colors for specific file extensions. Key/value pairs will extend the [default colors](https://github.com/githubocto/repo-visualizer/pull/src/language-colors.json).
    file_colors: # optional, default is {}

- name: TF Visualizer Action
  # You may pin to the exact commit or the version.
  # uses: fatihtokus/tf-visualizer-action@6416eec127a9ba20058cc3a1d3aa9c7a7e57dac1
  uses: fatihtokus/tf-visualizer-action@v1.2
  with:
    # Who to greet
    who-to-greet: # default is World
- name: action-visual-snapshot
  # You may pin to the exact commit or the version.
  # uses: getsentry/action-visual-snapshot@57170d7adac305cb012a68e59551f1273c5abc5e
  uses: getsentry/action-visual-snapshot@v2.0.0
  with:
    # Matching threshold, ranges from 0 to 1. Smaller values make the comparison more sensitive. 0.1 by default.
    threshold: # optional, default is 0.05
    # If true, disables detecting and ignoring anti-aliased pixels. false by default.
    includeAA: # optional
    # Blending factor of unchanged pixels in the diff output. Ranges from 0 for pure white to 1 for original brightness. 0.1 by default.
    alpha: # optional, default is 0.1
    # Draw the diff over a transparent background (a mask), rather than over the original image. Will not draw anti-aliased pixels (if detected).
    diffMask: # optional
    # path where snapshots are saved
    snapshot-path: # optional
    # the merge base sha, will use from github context otherwise. If you use `pull_request_target` you will need to supply the merge base.
    merge-base: # optional
    # Visual Snapshot API token, should be `VISUAL_SNAPSHOT_SECRET` from GitHub Secrets
    api-token: 
    # Custom API endpoint
    api-endpoint: # optional
    # github token
    github-token: # optional, default is ${{ github.token }}
    # path to write snapshot diffs
    results-path: # optional, default is /tmp/visual-snapshot-results
    # should action only be used to save snapshots
    save-only: # optional
    # id of the workflow that saves your base snapshots (the name of the yaml file including extension)
    base-workflow-id: # optional
    # name of the branch to use as base comparison
    base-branch: # optional, default is master
    # the artifact name
    artifact-name: # optional, default is visual-snapshots
    # The name to be displayed in GitHub Checks
    action-name: # optional, default is Visual Snapshot
    # Google Cloud service account key (base64)
    gcp-service-account-key: # optional
    # if this is set, upload to google cloud storage
    gcs-bucket: # optional


    - name: Visual Studio VSIX Signer
  # You may pin to the exact commit or the version.
  # uses: CalvinAllen/action-vs-vsix-signer@8438c803e77f40b58930b0caff1911e0225fc49b
  uses: CalvinAllen/action-vs-vsix-signer@v1
  with:
    # Relative path to your publish manifest
    sign-certificate-path: 
    # Relative path to your VSIX file
    vsix-path: 
    # The password for your certificate file
    sign-password: 
    # Version of Visual Studio to search; defaults to latest if not specified
    vs-version: # optional
    # Enable searching for pre-release versions of Visual Studio
    vs-prerelease: # optional


    - name: Visual Studio Marketplace Publisher
  # You may pin to the exact commit or the version.
  # uses: CalvinAllen/action-vs-marketplace-publish@95d0ed2b06b0368f9997925ac8b4b9c27e61f26a
  uses: CalvinAllen/action-vs-marketplace-publish@v1
  with:
    # Your personal access token for the Marketplace
    marketplace-pat: 
    # Relative path to your publish manifest
    publish-manifest-path: 
    # Relative path to your VSIX file
    vsix-path: 
    # Version of Visual Studio to search; defaults to latest if not specified
    vs-version: # optional
    # Enable searching for pre-release versions of Visual Studio
    vs-prerelease: # optional

    - name: Version Visual Studio SDK projects
  # You may pin to the exact commit or the version.
  # uses: roryprimrose/set-vs-sdk-project-version@a3f300b86a779fcdeea2c5d586ee9415c64cc42a
  uses: roryprimrose/set-vs-sdk-project-version@v1.0.6
  with:
    # The wildcard filter that identifies projects to version
    projectFilter: # default is **/*.*proj
    # Maps to the Version element
    version: # optional
    # Maps to the AssemblyVersion element
    assemblyVersion: # optional
    # Maps to the FileVersion element
    fileVersion: # optional
    # Maps to the InformationalVersion element
    informationalVersion: # optional
- name: Visualize google cloud build graph
  # You may pin to the exact commit or the version.
  # uses: gecko655/github-action-visualize-gcb-graph@aba569609bb086c13f49f4685afaf259b5aca67b
  uses: gecko655/github-action-visualize-gcb-graph@v0.0.3
  with:
    # The version of https://github.com/RyanSiu1995/gcb-visualizer, starts with "v"
    gcb-visualizer-version: # optional, default is v1.0.1
    # Comma separated list of dictionaries that cloudbuild.yaml files are searched
    search-directories: # optional, default is .
    # Custom pattern for the "cloudbuild.yaml" file name. This value is used as a parameter of `find -name`. See: https://man7.org/linux/man-pages/man1/find.1.html
    filename-find-pattern: # optional, default is cloudbuild.yaml
    # Output directory of the output visualized image files. This value is used as a relative path from the path of the directory of the cloudbuild.yaml
    output-directory-relative-path: # optional, default is images
    # The file extension of the output visualized image files. See https://github.com/RyanSiu1995/gcb-visualizer#current-features to check available options
    output-filetype: # optional, default is png

  - name: Automating Image Classification with Microsoft Azure Custom Vision Training and Prediction
  # You may pin to the exact commit or the version.
  # uses: mritunjaysharma394/autoCustomVision@13b561225f4a22402341cbce9ed7f83b3d32012b
  uses: mritunjaysharma394/autoCustomVision@v1.0
  with:
    # Allow user to enter tags for classification
    tags: 
    # The file name patter used
    tagsVar: # optional
    # The training size of each tag
    trainSize: 
    # The endpoint required to connect with Azure Custom Vision
    endpoint: 
    # The training key for Azure Custom Vision Service
    trainingKey: 
    # The prediction key for Azure Custom Vision Service
    predictionKey: 
    # The Prediction Source ID for Azure Custom Vision Service
    predictionResourceid: 
    - name: Source to Image Build
  # You may pin to the exact commit or the version.
  # uses: redhat-actions/s2i-build@338d362878e811df2022261728b493e11de1d14c
  uses: redhat-actions/s2i-build@v2
  with:
    # The path of the s2i builder image.
    builder_image: 
    # The Name of the image to build
    image: 
    # The tags of the image to build. For multiple tags, seperate by a space. For example, "latest v1".
    tags: # optional, default is latest
    # The location of the path to run s2i from
    path_context: # optional, default is .
    # Log level when running the S2I
    log_level: # optional, default is 1
    # List of environment variable key-value pairs to pass to the s2i builder context
    env_vars: # optional
    # Include all files in tar during build which includes .git directory
    include_git: # optional, default is false

    - name: Setup Android NDK >=23
  # You may pin to the exact commit or the version.
  # uses: anoop-b/setup-ndk@6f0ee78e62451cfec5f1698acb00b58d00a5d7b6
  uses: anoop-b/setup-ndk@V1.3.0
  with:
    # Exact version to use
    ndk-version: 
    # Add installation directory to the PATH
    add-to-path: # optional, default is true
    # Use the local job cache on top of the runner tool cache
    local-cache: # optional, default is false
    
    - name: Get Runs From Weights & Biases
  # You may pin to the exact commit or the version.
  # uses: machine-learning-apps/wandb-action@ea8c99cb8230d7ec3d1bbe087a5f1853843b93b9
  uses: machine-learning-apps/wandb-action@1.1

  - name: Sync a Repo like subdir of another
  # You may pin to the exact commit or the version.
  # uses: tomasdelvechio/actions-push-repo-to-subdir@03a931ed94be8fa004c56ca0c28c73bbd20f4e55
  uses: tomasdelvechio/actions-push-repo-to-subdir@v1.2.0
  with:
    # User of github
    github-username: 
    # Subdir name on target repo
    target-subdir-name: 

    - name: Docker Buildx Bake
  # You may pin to the exact commit or the version.
  # uses: docker/bake-action@f32f8b8d70bc284af19f8148dd14ad1d2fbc6c28
  uses: docker/bake-action@v3.1.0
  with:
    # Builder instance
    builder: # optional
    # List of bake definition files
    files: 
    # Working directory of bake execution
    workdir: # optional, default is .
    # List of bake targets
    targets: # optional
    # Do not use cache when building the image
    no-cache: # optional, default is false
    # Always attempt to pull a newer version of the image
    pull: # optional, default is false
    # Load is a shorthand for --set=*.output=type=docker
    load: # optional, default is false
    # Provenance is a shorthand for --set=*.attest=type=provenance
    provenance: # optional
    # Push is a shorthand for --set=*.output=type=registry
    push: # optional, default is false
    # SBOM is a shorthand for --set=*.attest=type=sbom
    sbom: # optional
    # List of targets values to override (eg. targetpattern.key=value)
    set: # optional
    # Remote bake definition to build from
    source: # optional
   - name: AutoSync branches
  # You may pin to the exact commit or the version.
  # uses: danielthedifficult/Action-AutoSync-Branches@c4bf6ab2758ae371d37464bd171e54c5e35eba3f
  uses: danielthedifficult/Action-AutoSync-Branches@v1.0.0
  
- name: Mirror Branch
  # You may pin to the exact commit or the version.
  # uses: zofrex/mirror-branch@0be56f4c8077a288a635a491b306ba0bb1c810e6
  uses: zofrex/mirror-branch@v1.0.4
  with:
    # Branch to mirror to
    target-branch: # optional, default is master
    # Token used to access the Github API. You can leave this as the default and Github will automatically provision one for you for this action.

    token: # optional, default is ${{ github.token }}
    # Whether to force push when updating the target branch. true = force push, false = don't force push.

    force: # optional, default is true

  - name: Bump.sh
  # You may pin to the exact commit or the version.
  # uses: bump-sh/github-action@c35e66ae2e9a08d338a7dac0dde89e7884de8796
  uses: bump-sh/github-action@v1.1.7
  with:
    # Relative path to the documentation file
    file: # default is api-contract.yml
    # Documentation id. Can be found in the documentation settings on https://bump.sh
    doc: # optional
    # Documentation token. Can be found in the documentation settings on https://bump.sh
    token: # optional
    # Hub slug or id. Needed when deploying to a documentation attached to a Hub. Can be found in the hub settings on https://bump.sh
    hub: # optional
    # Branch name used during `deploy` or `diff` commands. This can be useful to maintain multiple API reference history and make it available in your API documentation.
    branch: # optional
    # Bump command: deploy|dry-run|preview|diff
    command: # optional, default is deploy
    # Specify a longer expiration date for public diffs (defaults to 1 day). Use iso8601 format to provide a date, or you can use `never` to keep the result live indefinitely.
    expires: # optional
    # Mark the action as failed when a breaking change is detected with the diff command. This is only valid when `diff` is provided in the command input.
    fail_on_breaking: # optional
    - name: bicep-build-output
  uses: Azure/bicep-build-action@v1.0.1
  with:
    # Bicep main file path
    bicepFilePath: # default is ./main.bicep
    # ARM template output path
    outputFilePath: # optional, default is ./azuredeploy.json

  - name: Setup Java Development Kits built by Oracle
  # You may pin to the exact commit or the version.
  # uses: oracle-actions/setup-java@1f72fc84c0ae0b8ac40bfa0cfb3935ac9a28ffb7
  uses: oracle-actions/setup-java@v1.3.1
  with:
    # Site to download JDK from: `oracle.com` or `jdk.java.net`
    website: # default is oracle.com
    # Feature release number or project name, defaults to `19`
    release: # default is 19
    # Additional version information, defaults to `latest`
    version: # default is latest
    # Install the downloaded JDK archive file by running actions/setup-java, defaults to `true`
    install: # default is true
    # Controls which value is passed as `java-version` to actions/setup-java, defaults to `PARSE_URI` if `release` starts with a digit, else it defaults to `HASH_URI`
    install-as-version: # optional
    # URI of JDK archive file to download
    uri: # optional


    - name: Okteto Build
  # You may pin to the exact commit or the version.
  # uses: okteto/build@853cad7b0e304456cf32efdc053aefa734feda2a
  uses: okteto/build@2.19.0
  with:
    # Name and tag in the "name:tag" format
    tag: # optional
    # Name of the Dockerfile (Default is "Dockerfile")
    file: # optional, default is Dockerfile
    # The path
    path: # optional, default is .
    # Use buildargs when you want to pass a list of environment variables as build-args
    buildargs: # optional
    # Use global when you want to make the image availbale to everyone in your team
    global: # optional

    - name: Bandit Scan
  # You may pin to the exact commit or the version.
  # uses: shundor/python-bandit-scan@9cc5aa4a006482b8a7f91134412df6772dbda22c
  uses: shundor/python-bandit-scan@v1.0
  with:
    # File or directory to run bandit on
    path: # optional, default is .
    # Report only issues of a given severity level or higher. Can be LOW, MEDIUM or HIGH. Default is UNDEFINED (everything)
    level: # optional, default is UNDEFINED
    # Report only issues of a given confidence level or higher. Can be LOW, MEDIUM or HIGH. Default is UNDEFINED (everything)
    confidence: # optional, default is UNDEFINED
    # comma-separated list of paths (glob patterns supported) to exclude from scan (note that these are in addition to the excluded paths provided in the config file) (default: .svn,CVS,.bzr,.hg,.git,__pycache__,.tox,.eggs,*.egg)
    excluded_paths: # optional, default is DEFAULT
    # exit with 0, even with results found
    exit_zero: # optional, default is DEFAULT
    # comma-separated list of test IDs to skip
    skips: # optional, default is DEFAULT
    # path to a .bandit file that supplies command line arguments
    ini_path: # optional, default is DEFAULT
    # Github token of the repository (automatically created by Github)
    GITHUB_TOKEN: 


    - name: Kubernetes bake
  uses: Azure/k8s-bake@v2
  with:
    # Acceptable values: helm or kompose or kustomize
    renderEngine: 
    # Required if renderEngine == helm. Helm chart to bake.
    helmChart: # optional
    # Relevant if renderEngine == helm. Namespace to be used for Helm option.
    namespace: # optional
    # Acceptable values: helm or kustomize. Arguments to be passed to the Helm or kustomize template command
    arguments: # optional
    # Relevant if renderEngine == helm. Array of path to override files. Each path should be mentioned on a newline
    overrideFiles: # optional
    # Relevant if renderEngine == helm. Override values to set.
    overrides: # optional
    # Relevant if renderEngine == helm. Release name to be used for Helm option.
    releaseName: # optional
    # Required if renderEngine == kustomize. Path to directory or the Git repository containing kustomization.yaml file.
    kustomizationPath: # optional
    # Required if renderEngine == kompose. Path(s) to Docker compose files
    dockerComposeFile: # optional
    # Version of kubectl. Installs a specific version of helm binary
    helm-version: # optional
    # Version of kubectl. Installs a specific version of kubectl binary
    kubectl-version: # optional
    # Version of kubectl. Installs a specific version of kompose binary
    kompose-version: # optional
    # When set to true, the output of the bake command would not be shown.
    silent: # optional


    - name: Bearer Security
  # You may pin to the exact commit or the version.
  # uses: Bearer/bearer-action@337e5e384c88d5dea466adcca6077dc48ebf1ed9
  uses: Bearer/bearer-action@v2
  with:
    # Specify the Bearer version to use. This must match a Bearer release name.
    version: # optional, default is 
    # Specify the comma separated scanners e.g. --scanner secrets,sast
    scanner: # optional, default is 
    # configuration file path
    config-file: # optional, default is 
    # Specify the comma-separated ids of the rules you would like to run. Skips all other rules.
    only-rule: # optional, default is 
    # Specify the comma-separated ids of the rules you would like to skip. Runs all other rules.
    skip-rule: # optional, default is 
    # Specify the comma separated files and directories to skip. Supports * syntax, e.g. --skip-path users/*.go,users/admin.sql
    skip-path: # optional, default is 
    # Specify the comma-separated fingerprints of the findings you would like to exclude from the report.
    exclude-fingerprint: # optional, default is 
    # Specify which severities are included in the report as a comma separated string
    severity: # optional, default is 
    # Specify which format to use for the report (json, yaml, sarif, gitlab-sast)
    format: # optional, default is 
    # Specify where to store the report
    output: # optional, default is 
    # For use with Bearer Cloud
    api-key: # optional, default is 
    # Enable differential scanning. Only supported for pull request events
    diff: # optional, default is false
    # Forces the exit-code when errors are reported
    exit-code: # optional, default is 
    
    - name: Docker Build Tag Publish
  # You may pin to the exact commit or the version.
  # uses: bitovi/github-actions-docker-publish@def3cb9a3ef842b230bf575dc4f5e280ae6a6896
  uses: bitovi/github-actions-docker-publish@v1.0.7
  with:
    # Checkout the repository
    checkout: # optional, default is true
    # Tag to override default Logic
    image_tag: # optional, default is 
    # Use the SHA for the tag.  Overrides the default logic.
    use_sha: # optional, default is false
    # Docker org name.
    org_name: # optional, default is 
    # Name of the docker repository
    repo_name: # optional, default is 
    # Tag default branch with latest tag instead of branch name.
    use_latest: # optional, default is true
    # Docker user
    docker_username: 
    # Docker password
    docker_password: 
    # Add a string of values to the end of the build command
    build_args: # optional
    # Specify the working directory that the docker build will be run in
    working-directory: # optional

- name: Docker Build Tag Publish
  # You may pin to the exact commit or the version.
  # uses: bitovi/github-actions-docker-publish@def3cb9a3ef842b230bf575dc4f5e280ae6a6896
  uses: bitovi/github-actions-docker-publish@v1.0.7
  with:
    # Checkout the repository
    checkout: # optional, default is true
    # Tag to override default Logic
    image_tag: # optional, default is 
    # Use the SHA for the tag.  Overrides the default logic.
    use_sha: # optional, default is false
    # Docker org name.
    org_name: # optional, default is 
    # Name of the docker repository
    repo_name: # optional, default is 
    # Tag default branch with latest tag instead of branch name.
    use_latest: # optional, default is true
    # Docker user
    docker_username: 
    # Docker password
    docker_password: 
    # Add a string of values to the end of the build command
    build_args: # optional
    # Specify the working directory that the docker build will be run in
    working-directory: # optional


    - name: Accessibility alt text bot
  uses: github/accessibility-alt-text-bot@v1.3.0
  
   - name: Run MATLAB Build
  # You may pin to the exact commit or the version.
  # uses: matlab-actions/run-build@735e80f87d8506207bbeeca61f4a81f129eba499
  uses: matlab-actions/run-build@v1.1.1
  with:
    # Space-separated list of tasks to run
    tasks: # optional, default is 
    # Startup options for MATLAB
   startup-options: # optional, default is 

    - name: Create Database Branch 
  # You may pin to the exact commit or the version.
  # uses: planetscale/create-branch-action@32b729c7b708e4c675bec1895c27378858d049a8
  uses: planetscale/create-branch-action@v4
  with:
    # The name of the database
    database_name: 
    # The name of the new branch
    branch_name: 
    # The name of the organization that owns the database
    org_name: 
    # The production branch to create the new branch from. Defaults to the default production branch.
    from: # optional
    # The ID of the backup you wish to restore into the new branch.
    restore: # optional
    # The region where the new branch should be created. Defaults to the region of the `from` branch.
    region: # optional
    # If set to "true", the action will wait until the branch is finished initializing before exiting.
    wait: # optional
    # If set to "true", the action won't create the branch if it already exists.
    check_exists: # optional
    # Set to "true", to enable seed data from the latest backup using Data Branching™
    seed_data: # optional
- name: Bridgecrew Github Action
  # You may pin to the exact commit or the version.
  # uses: bridgecrewio/bridgecrew-action@e388196ade022d4c6f28c368c4428b05e4f5d33a
  uses: bridgecrewio/bridgecrew-action@v1.177.2
  with:
    # directory with infrastructure code to scan
    directory: # optional, default is .
    # Run scan only on a specific check identifier (comma separated)
    check: # optional
    # Run scan on all checks but a specific check identifier (comma separated)
    skip_check: # optional
    # display only failed checks
    quiet: # optional
    # Environment variable name of the Bridgecrew API key from Bridgecrew app
    api-key: # optional
    # Runs checks but suppresses error code
    soft-fail: # optional
    # Directory for custom checks to be loaded
    external-checks-dir: # optional
    # Output Format (cli, cli+sarif, json, junitxml)
    output_format: # optional, default is sarif
- name: Trigger Mobile Builds with Appflow
  # You may pin to the exact commit or the version.
  # uses: ionic-team/appflow-build@71a31db2d31237f18473cb3235fa7c27302136dc
  uses: ionic-team/appflow-build@v1
  with:
    # A token used to authenticate with the Appflow Service.
    token: 
    # The Appflow App ID to trigger the build for.
    app-id: 
    # The platform to build for (Web, iOS, Android)
    platform: # default is Web
    # The type of build to perform. iOS - (ad-hoc, app-store, development, enterprise) Android - (debug, release)
    build-type: # optional
    # The build stack to use for the build (macOS - 2020.06, Linux - 2020.06, etc.)
    build-stack: # optional
    # The name of the signing certificate to use for the build.
    certificate: # optional
    # The name of the environment to use for the build.
    environment: # optional
    # The name of the native config to use for the build.
    native-config: # optional
    # A comma seperated list of destination names to trigger a deployment to on successful completion of build.
    destinations: # optional
    # If the platform is Web set this to [yes|no] to control whether a web preview is created for the build.
    web-preview: # optional, default is no
    # The filename to use for the IPA/APK (iOS, Android) defaults to {{workflow_name}}-{{run_id}}.[apk|ipa]
    filename: # optional
    # If this is set if any artifacts are created (APK/IPA) they will be uploaded as the name that is specified
    upload-artifact: # optional
    # Set this to determine the number of days to retain the uploaded artifact [1-90](defaults to 90).
    artifact-retention-days: # optional, default is 90
- name: Appdome build-2secure
  # You may pin to the exact commit or the version.
  # uses: Appdome/github_build-2secure@6162472516463311583acd4997d895e2f7f6838e
  uses: Appdome/github_build-2secure@1.1.4
  with:
    # Appdome API key
    APPDOME_API_TOKEN: # default is None
    # APK file
    APP_FILE: # default is None
    # Appdome FusionSetId iOS/Android
    FUSION_SET_ID: # default is None
    # iOS/Android Signin option
    SIGN_OPTIONS: 
    # Keystore sign file
    KEYSTORE_FILE: # optional, default is None
    # iOS sign file
    MOBILE_PROVISION_PROFILE_FILE: # optional, default is None
    # iOS sign file
    ENTITLEMENTS_FILE: # optional, default is None
    # Keystore password sign file
    KEYSTORE_PASSWORD: # optional, default is None
    # keystore alias
    KEYSTORE_ALIAS: # optional, default is None
    # keystore key password
    KEYSTORE_KEY_PASSWORD: # optional, default is None
    # signing sha1 fingerprint
    SIGN_FINGERPRINT: # optional, default is None
    # Google Play App Signing program
    GOOGLE-PLAY-SIGNING: # optional, default is false
    # your team-id
    TEAM-ID: # optional, default is None
    # whether build with logs or not
    BUILD_WITH_LOGS: # optional
    # Should there be a second universal apk output (for aab apps)?
    SECOND_OUTPUT: # optional
    # Build to test option
    BUILD_TO_TEST: # optional, default is None

    
    - name: Docker Setup Buildx
  # You may pin to the exact commit or the version.
  # uses: docker/setup-buildx-action@4c0219f9ac95b02789c1075625400b2acbff50b1
  uses: docker/setup-buildx-action@v2.9.1
  with:
    # Buildx version. (eg. v0.3.0)
    version: # optional
    # Sets the builder driver to be used
    driver: # optional, default is docker-container
    # List of additional driver-specific options. (eg. image=moby/buildkit:master)
    driver-opts: # optional
    # Flags for buildkitd daemon
    buildkitd-flags: # optional, default is --allow-insecure-entitlement security.insecure --allow-insecure-entitlement network.host
    # Sets up docker build command as an alias to docker buildx build
    install: # optional, default is false
    # Switch to this builder instance
    use: # optional, default is true
    # Optional address for docker socket or context from `docker context ls`
    endpoint: # optional
    # Fixed platforms for current node. If not empty, values take priority over the detected ones
    platforms: # optional
    # BuildKit config file
    config: # optional
    # Inline BuildKit config
    config-inline: # optional
    # Append additional nodes to the builder
    append: # optional
    # Cleanup temp files and remove builder at the end of a job
    cleanup: # optional, default is true

    - name: Frogbot by JFrog
  # You may pin to the exact commit or the version.
  # uses: jfrog/frogbot@dcb8fe0ddf9698edb9439802b061d347b7013be5
  uses: jfrog/frogbot@v2.12.2
  with:
    # Frogbot version
    version: # optional, default is latest
- name: Download a Build Artifact
  uses: actions/download-artifact@v2.1.1
  with:
    # Artifact name
    name: # optional
    # Destination path
    path: # optional

    - name: brew-dependency-submission-action
  # You may pin to the exact commit or the version.
  # uses: advanced-security/brew-dependency-submission-action@25113069cbb9f839378acfd72dadc90692c94a53
  uses: advanced-security/brew-dependency-submission-action@v1.1
  with:
    # Brew Lockfile location
    brew-lock: # optional
    # Repository Owner and Repository Name
    repository: # optional, default is ${{ github.repository }}
    # GitHub Personal Access Token
    token: # optional, default is ${{ github.token }}
    # Additional Arguments
    argvs: # optional

    - name: Upload a Build Artifact
  uses: actions/upload-artifact@v3.1.2
  with:
    # Artifact name
    name: # optional, default is artifact
    # A file, directory or wildcard pattern that describes what to upload
    path: 
    # The desired behavior if no files are found using the provided path.
Available Options:
  warn: Output a warning but do not fail the action
  error: Fail the action with an error message
  ignore: Do not output any warnings or errors, the action does not fail

    if-no-files-found: # optional, default is warn
    # Duration after which artifact will expire in days. 0 means using default retention.
Minimum 1 day. Maximum 90 days unless changed from the repository settings page.

    retention-days: # optional
- name: ZAP Baseline Scan
  # You may pin to the exact commit or the version.
  # uses: zaproxy/action-baseline@41aee98ebc7cf2802c3beae4e7d4336413a21e43
  uses: zaproxy/action-baseline@v0.9.0
  with:
    # GitHub Token to create issues in the repository
    token: # optional, default is ${{ github.token }}
    # Target URL
    target: 
    # Relative path of the ZAP configuration file
    rules_file_name: # optional
    # The Docker file to be executed
    docker_name: # default is ghcr.io/zaproxy/zaproxy:stable
    # Additional command line options
    cmd_options: # optional
    # The title for the GitHub issue to be created
    issue_title: # optional, default is ZAP Scan Baseline Report
    # The action status will be set to fail if ZAP identifies any alerts during the baseline scan
    fail_action: # optional
    # The action will file the report to the GitHub issue using the issue_title input
    allow_issue_writing: # optional, default is true
    # The name of the artifact that contains the ZAP reports
    artifact_name: # optional, default is zap_scan

- name: Renovate Bot GitHub Action
  # You may pin to the exact commit or the version.
  # uses: renovatebot/github-action@aa150c86873c3e1326734d9c1390064fbc646148
  uses: renovatebot/github-action@v36.0.0
  with:
    # Configuration file to configure Renovate. Either use this input or the
'RENOVATE_CONFIG_FILE' environment variable.

    configurationFile: # optional
    # GitHub personal access token that Renovate should use. This should be
configured using a Secret. Either use this input or the 'RENOVATE_TOKEN'
environment variable.

    token: # optional
    # Use a lightweight renovate container without any third-party binaries.
Defaults to true if not set.

    useSlim: # optional
    # Override the environment variables which will be passsed into the renovate container.
Defaults to `^(?:RENOVATE_\\w+|LOG_LEVEL|GITHUB_COM_TOKEN|NODE_OPTIONS)$`

    env-regex: # optional
    # Renovate version to use. Defaults to latest.

    renovate-version: # optional

    - name: Build and push Docker images
  # You may pin to the exact commit or the version.
  # uses: docker/build-push-action@2eb1c1961a95fc15694676618e422e8ba1d63825
  uses: docker/build-push-action@v4.1.1
  with:
    # List of a customs host-to-IP mapping (e.g., docker:10.180.0.1)
    add-hosts: # optional
    # List of extra privileged entitlement (e.g., network.host,security.insecure)
    allow: # optional
    # List of attestation parameters (e.g., type=sbom,generator=image)
    attests: # optional
    # List of build-time variables
    build-args: # optional
    # List of additional build contexts (e.g., name=path)
    build-contexts: # optional
    # Builder instance
    builder: # optional
    # List of external cache sources for buildx (e.g., user/app:cache, type=local,src=path/to/dir)
    cache-from: # optional
    # List of cache export destinations for buildx (e.g., user/app:cache, type=local,dest=path/to/dir)
    cache-to: # optional
    # Optional parent cgroup for the container used in the build
    cgroup-parent: # optional
    # Build's context is the set of files located in the specified PATH or URL
    context: # optional
    # Path to the Dockerfile
    file: # optional
    # List of metadata for an image
    labels: # optional
    # Load is a shorthand for --output=type=docker
    load: # optional, default is false
    # Set the networking mode for the RUN instructions during build
    network: # optional
    # Do not use cache when building the image
    no-cache: # optional, default is false
    # Do not cache specified stages
    no-cache-filters: # optional
    # List of output destinations (format: type=local,dest=path)
    outputs: # optional
    # List of target platforms for build
    platforms: # optional
    # Generate provenance attestation for the build (shorthand for --attest=type=provenance)
    provenance: # optional
    # Always attempt to pull all referenced images
    pull: # optional, default is false
    # Push is a shorthand for --output=type=registry
    push: # optional, default is false
    # Generate SBOM attestation for the build (shorthand for --attest=type=sbom)
    sbom: # optional
    # List of secrets to expose to the build (e.g., key=string, GIT_AUTH_TOKEN=mytoken)
    secrets: # optional
    # List of secret files to expose to the build (e.g., key=filename, MY_SECRET=./secret.txt)
    secret-files: # optional
    # Size of /dev/shm (e.g., 2g)
    shm-size: # optional
    # List of SSH agent socket or keys to expose to the build
    ssh: # optional
    # List of tags
    tags: # optional
    # Sets the target stage to build
    target: # optional
    # Ulimit options (e.g., nofile=1024:1024)
    ulimit: # optional
    # GitHub Token used to authenticate against a repository for Git context
    github-token: # optional, default is ${{ github.token }}
    
    
    
    
      - name: SecureStack Application Bill of Materials (ABOM/SBOM)
  # You may pin to the exact commit or the version.
  # uses: SecureStackCo/actions-abom@79918764749124140413963295aee5e4430a5564
  uses: SecureStackCo/actions-abom@v0.1.5
  with:
    # SecureStack API key - generate one at https://app.securestack.com
    securestack_api_key: 
    # SecureStack Application ID - available when viewing applications at https://app.securestack.com
    securestack_app_id: 
    # Severities lower than this input value will not be reported; value should be one of: critical | high | medium | low
    severity: 
    # Optional flags for the bloodhound-cli SBOM command - run bloodhound-cli SBOM --help for more details.
    flags: # optional, default is 
    
    - name: Postgres Docker image with "baked-in" data
  # You may pin to the exact commit or the version.
  # uses: snaplet/publish-postgres-with-data-docker-action@6b93fedc6f8152823fda26d1fe10330ae94299d1
  uses: snaplet/publish-postgres-with-data-docker-action@v1.0.0
  with:
    # Name of docker database container
    docker-container-name: 
    # Tag for docker image
    docker-image-tag: 
    # Connection string to restore a snapshot
    snaplet-database-url: 
    # Command used to restore a snapshot
    snaplet-restore-command: # optional, default is snaplet snapshot restore --latest

    
  - name: Build Jekyll for GitHub Pages
  uses: actions/jekyll-build-pages@v1.0.8
  with:
    # Directory where the source files reside.
    source: # optional, default is ./
    # Output directory of the build. Although it can be nested inside the source, it cannot be the same as the source directory.
    destination: # optional, default is ./_site
    # Publishes posts with a future date. When set to true, the build is made with the --future option which overrides the future option that may be set in a Jekyll configuration file.
    future: # optional
    # The SHA-1 of the git commit for which the build is running. Default to GITHUB_SHA.
    build_revision: # optional, default is ${{ github.sha }}
    # Verbose output
    verbose: # optional, default is true
    # GitHub token
    token: # default is ${{ github.token }}
    
    
- name: Build Azure Virtual Machine Image
  uses: Azure/build-vm-image@v0
  with:
    # This is the Azure region in which the Image Builder will run.
    location: # optional
    # This is the Resource Group where the temporary Imagebuilder Template resource will be created.
    resource-group-name: 
    # The name of the image builder template resource to be used for creating and running the Image builder service.
    image-builder-template-name: # optional
    # The value is an integer which is used as timeout in minutes for running the image build.
    build-timeout-in-minutes: # optional, default is 240
    # You can override the VM size, from the default value i.e. Standard_D1_v2.
    vm-size: # optional, default is Standard_D1_v2
    # The identity that will be used to do the role assignment and resource creation
    managed-identity: # optional
    # [ PlatformImage | SharedImageGallery | ManagedImage ]
    source-image-type: # optional, default is PlatformImage
    # OS types supported: [ linux | windows ].
    source-os-type: 
    # Value of source-image supported by Azure Image Builder.
    source-image: # optional
    # This takes the path to a directory or a file in the runner. By default, it points to the default download directory of the github runner.
    customizer-source: # optional
    # The customer can enter multi inline powershell or shell commands and use variables to point to directories inside the downloaded location.
    customizer-script: # optional
    # The value is boolean and set to false by default. This value is for Windows images only, the image builder will run Windows Update at the end of the customizations and also handle the reboots it requires.
    customizer-windows-update: # optional
    # ManagedImage | SharedImageGallery | VHD
    dist-type: # optional, default is ManagedImage
    # Image Resource Id to be created by AIB
    dist-resource-id: # optional
    # location of Image created by AIB
    dist-location: # optional
    # Every Image builder run is identified with a unique run id.
    run-output-name: # optional
    # The values set will be used to set the user defined tags on the custom image artifact created.
    dist-image-tags: # optional
    
    - name: Quality Clouds Build Check for Salesforce
  # You may pin to the exact commit or the version.
  # uses: qualityclouds/action-full-scan@4bc13bbfa27d8eaa0bc4978ac161d148a6f70ac4
  uses: qualityclouds/action-full-scan@1.0.1
  with:
    # You need to provide a valid API key to connect the Quality Clouds ruleset against which your code will be checked
    token: 
    # Use cloud mode to runh a Feature branch scan
    mode: # optional
    # The instance Id. Required when cloud mode is enabled.
    url_id: # optional
    # Use cloud mode to runh a Feature branch scan
    api_url: # optional
    # Customize runner version
    version: # optional

- name: Build Writerside docs using Docker
  # You may pin to the exact commit or the version.
  # uses: JetBrains/writerside-github-action@a054b95e21517ef3e24ae77782156c3aeeba964b
  uses: JetBrains/writerside-github-action@v4
  with:
    # Writerside docker image version
    docker-version: # optional
    # Module name and instance ID
    instance: 
    # Archive to store as artifact
    artifact: 
    
    - name: Liquibase Checks Bulk Set Action
  # You may pin to the exact commit or the version.
  # uses: liquibase-github-actions/checks-bulk-set@ddddcebee59290073e955eaa5360194d79617e86
  uses: liquibase-github-actions/checks-bulk-set@v4.23.1
  with:
    # Allows automatic backup and updating of liquibase.checks.conf file when new quality checks are available. Options: [on|off]
    autoUpdate: # optional
    # Relative or fully qualified path to a configuration file for checks execution
    checksSettingsFile: # optional
    # Disable all qualifying checks in the checks settings file
    disable: # optional
    # Enable all qualifying checks in the checks settings file
    enable: # optional
    # Do not ask for confirmation when running this command
    force: # optional
    # Set the severity of all checks to the value specified
    severity: # optional
    # If true, drop and recreate a view instead of replacing it.
    alwaysDropInsteadOfReplace: # optional
    # When generating SQL for createProcedure, should the procedure schema be forced to the default schema if no schemaName attribute is set?
    alwaysOverrideStoredLogicSchema: # optional
    # Should Liquibase automatically include REORG TABLE commands when needed?
    autoReorg: # optional
    # Number of seconds wait between checks to the changelog lock when it is locked
    changelogLockPollRate: # optional
    # Number of minutes to wait for the changelog lock to be available before giving up
    changelogLockWaitTimeInMinutes: # optional
    # Configures how to handle unknown fields in changelog files. Possible values: STRICT which causes parsing to fail, and LAX which continues with the parsing.
    changelogParseMode: # optional
    # Additional classpath entries to use
    classpath: # optional
    # Should Liquibase convert to/from STANDARD data types. Applies to both snapshot and update commands.
    convertDataTypes: # optional
    # [PRO]Relative or fully qualified path to a yaml file containing key:value data to inject or exclude data from JSON structured logs. Learn more at https://docs.liquibase.com/structured-logging
    customLogDataFile: # optional
    # Name of table to use for tracking concurrent Liquibase usage
    databaseChangelogLockTableName: # optional
    # Name of table to use for tracking change history
    databaseChangelogTableName: # optional
    # Class to use for Database implementation
    databaseClass: # optional
    # The DDL_LOCK_TIMEOUT parameter indicates the number of seconds a DDL command should wait for the locks to become available before throwing the resource busy error message. This applies only to Oracle databases.
    ddlLockTimeout: # optional
    # File with default Liquibase properties
    defaultsFile: # optional
    # Should Liquibase compare column order in diff operation?
    diffColumnOrder: # optional
    # Database driver class
    driver: # optional
    # Driver-specific properties
    driverPropertiesFile: # optional
    # How to handle multiple files being found in the search path that have duplicate paths. Options are WARN (log warning and choose one at random) or ERROR (fail current operation)
    duplicateFileMode: # optional
    # Throw an error if Liquibase detects that an includeAll will cause a circular reference (and thus a changelog parse error).
    errorOnCircularIncludeAll: # optional
    # Encoding to use when reading files. Valid values include: UTF-8, UTF-16, UTF-16BE, UTF-16LE, US-ASCII, or OS to use the system configured encoding.
    fileEncoding: # optional
    # DEPRECATED: No longer used
    filterLogMessages: # optional
    # If true, display a more verbose output for the FlowFile toString representation
    flowVerboseToString: # optional
    # Should Liquibase include a "created" attribute in diff/generateChangelog changesets with the current datetime
    generateChangesetCreatedValues: # optional
    # Should Liquibase include the change description in the id when generating changesets?
    generatedChangesetIdsContainsDescription: # optional
    # Force liquibase to think it has no access to a keyboard
    headless: # optional
    # Should Liquibase include the catalog name when determining equality?
    includeCatalogInSpecification: # optional
    # Include the system classpath when resolving classes at runtime
    includeSystemClasspath: # optional
    # Liquibase Pro or Liquibase Labs license key used to unlock paid capabilities. Get a free trial at https://liquibase.com/trial and use in CLI or add liquibase.licenseKey=<yourKey> into your defaults file.
    licenseKey: # optional
    # Catalog to use for Liquibase objects
    liquibaseCatalogName: # optional
    # Schema to use for Liquibase objects
    liquibaseSchemaName: # optional
    # Tablespace to use for Liquibase objects
    liquibaseTablespaceName: # optional
    # Controls which log channels have their level set by the liquibase.logLevel setting. Comma separate multiple values. To set the level of all channels, use "all". Example: liquibase,org.mariadb.jdbc
    logChannels: # optional
    # 
    logFile: # optional
    # Sets the format of log output to console or log files. Open Source users default to unstructured "TEXT" logs to the console or output log files. Pro users have the option to set value as "JSON" or "JSON_PRETTY" to enable json-structured log files to the console or output log files.
    logFormat: # optional
    # Controls which logs get set to stderr AND to any log file. The CLI defaults, if log file set, to SEVERE. Others vary by integration. The official log levels are: OFF, SEVERE, WARNING, INFO, FINE
    logLevel: # optional
    # When set to true, the console messages are mirrored to the logs as [liquibase.ui] to provide a more complete picture of liquibase operations to log analysis tools. Set to false to change this behavior.
    mirrorConsoleMessagesToLog: # optional
    # How to handle changelog property expressions where a value is not set. For example, a string "${address}" when no "address" property was defined. Values can be: "preserve" which leaves the string as-is, "empty" which replaces it with an empty string, or "error" which stops processing with an error.
    missingPropertyMode: # optional
    # Enable performance tracking. Set to "false" to disable. If set to "true", data is stored to a `liquibase-TIMESTAMP.jfr` file in your working directory. Any other value will enable tracking and be used as the name of the file to write the data to.
    monitorPerformance: # optional
    # Custom executor that can specified
    nativeExecutor: # optional
    # If set to WARN, then liquibase will not throw exception on missing changelog file, instead will show a warning message.
    onMissingIncludeChangelog: # optional
    # 
    outputFile: # optional
    # Encoding to use when writing files
    outputFileEncoding: # optional
    # Line separator for output
    outputLineSeparator: # optional
    # Should liquibase treat schema and catalog names as case sensitive?
    preserveSchemaCase: # optional
    # DEPRECATED: Liquibase Pro license key used to unlock paid capabilities. Get a free trial at https://www.liquibase.com/protrial and use in CLI or add liquibase.pro.licenseKey=<yourKey> into your defaults file.
    proLicenseKey: # optional
    # If a column would be dropped in a diffChangeLog, call markUnused instead if set to true
    proMarkUnusedNotDrop: # optional
    # If true, generate changeSets with SQL-based changes inlined instead of saving them to an external file
    proSqlInline: # optional
    # If false, do not drop public synonyms in diffChangeLog/dropAll
    proSynonymsDropPublic: # optional
    # Should Liquibase prompt if a non-local database is being accessed
    promptForNonLocalDatabase: # optional
    # Implementation of Properties class to provide additional driver properties
    propertyProviderClass: # optional
    # Complete list of Location(s) to search for files such as changelog files in. Multiple paths can be specified by separating them with commas.
    searchPath: # optional
    # If true, remove functionality from file parsers which could be used insecurely. Examples include (but not limited to) disabling remote XML entity support.
    secureParsing: # optional
    # Should Liquibase commands execute
    shouldRun: # optional
    # Should Liquibase snapshot data by default?
    shouldSnapshotData: # optional
    # If true, show a Liquibase banner on startup.
    showBanner: # optional
    # Level to log SQL statements to
    sqlLogLevel: # optional
    # Show SQLWarning messages
    sqlShowSqlWarnings: # optional
    # Be stricter on allowed Liquibase configuration and setup?
    strict: # optional
    # Support escaping changelog parameters using a colon. Example: ${:user.name}
    supportPropertyEscaping: # optional
    # If set to true (default value), createProcedure tags with a set schemaName will modify the procedure body with the given schema name.
    useProcedureSchema: # optional
    # Will perform xsd validation of XML changelog files. When many XML changelog files are included this validation may impact Liquibase performance. Defaults to true.
    validateXmlChangelogFiles: # optional
    
 - name: Internal App Sharing
  # You may pin to the exact commit or the version.
  # uses: sagar-viradiya/internal-app-sharing-action@64f6f1ddb046af97c5b67fed0dee7be0647fb1c3
  uses: sagar-viradiya/internal-app-sharing-action@v1.1.0
  with:
    # The service account json plain text private key file to authorize the upload request
    serviceAccountJsonPlainText: 
    # Package name of the application
    packageName: 
    # .apk file path
    apkFilePath: # optional
    # .aab file path
    aabFilePath: # optional

    
    
  - name: Upload AAB and download APK
  # You may pin to the exact commit or the version.
  # uses: TianchenWei/upload-aab-google-play@5ac73e13a419c32b8d174c00027ba5e8fdd0e044
  uses: TianchenWei/upload-aab-google-play@v1.0.0
  with:
    # Service account credential base64
    service-account-credential-base64: 
    # Package name
    package-name: 
    # aab file path
    aab-file-path: 
    
    - name: BundleTool Action APK
  # You may pin to the exact commit or the version.
  # uses: amirisback/bundletool-action-apk@3ce56aefccf1c13feef226074bd7b9d99a6718fa
  uses: amirisback/bundletool-action-apk@1.0.0
  with:
    # Path to your aab file
    aabFile: 
    # The key used to sign the apk encoded in base 64
    base64Keystore: 
    # The keystore password
    keystorePassword: 
    # The keystore alias
    keystoreAlias: 
    # The password to the key
    keyPassword: 
    # The version of bundletool to use
    bundletoolVersion: # optional, default is latest
    - name: Install Riff
  # You may pin to the exact commit or the version.
  # uses: DeterminateSystems/install-riff-action@b2b5b9784cf97c28261713494cbab422eaae1869
  uses: DeterminateSystems/install-riff-action@v1.0.3
  with:
    # The version of Riff to install
    riff-version: # optional, default is 1.0.3
    - name: install-pinned/setuptools
  # You may pin to the exact commit or the version.
  # uses: install-pinned/setuptools@f6344ca5c153b05a19a4bdf7782fec144dc01b10
  uses: install-pinned/setuptools@add-commit-hash-here
  - name: Try in Web IDE
  # You may pin to the exact commit or the version.
  # uses: redhat-actions/try-in-web-ide@11cfde83a356e5b6086bd67a9c5c135037317e4b
  uses: redhat-actions/try-in-web-ide@v1.4.2
  with:
    # GitHub token used to add PR comment and/or status check
    github_token: 
    # If 'true', the action will add comments on each PR with a link to try the PR in Web IDE
    add_comment: # optional, default is true
    # If 'true', the action will add a PR status check on each PR with a link to try the PR in Web IDE
    add_status: # optional, default is true
    # If 'true', the badge and status check URL created by the action will have Git remotes automatically configured
if the PR branch is located in a fork repo.
The fork repo and the base repo will be configured to be the 'origin' and 'upstream' remote respectively.
The Web IDE must be based on Eclipse Che® 7.60 for this feature.

    setup_remotes: # optional, default is false
    # The base url for the Web IDE instance
    web_ide_instance: # optional, default is https://workspaces.openshift.com
    # The badge url for the comment created when 'add_comment' is 'true'
    comment_badge: # optional, default is https://img.shields.io/badge/Eclipse_Che-Hosted%20by%20Red%20Hat-525C86?logo=eclipse-che&labelColor=FDB940
    - name: Create Release in Octopus Deploy
  # You may pin to the exact commit or the version.
  # uses: OctopusDeploy/create-release-action@1c3646c1c965bdf299ae40ab04861cf2017e2b01
  uses: OctopusDeploy/create-release-action@v3.0.5
  with:
    # The name of the project associated with this release.
    project: 
    # The number for the new release. If omitted, Octopus Deploy will generate a release number.
    release_number: # optional
    # The name of the channel to use for the new release. If omitted, the best channel will be selected based on channel version rules.
    channel: # optional
    # The default version number of all packages to use for this release.
    package_version: # optional
    # A multi-line list of version numbers to use for a package in the release. Format: StepName:Version or PackageID:Version or StepName:PackageName:Version. StepName, PackageID, and PackageName can be replaced with an asterisk ("*"). An asterisk will be assumed for StepName, PackageID, or PackageName if they are omitted.
    packages: # optional
    # Git branch reference to the specific resources of a version controlled Octopus Project. This is required for version controlled projects.
    git_ref: # optional
    # Git commit pointing to the specific resources of a version controlled Octopus Project. If empty, it will use the HEAD from the corresponding gitRef parameter.
    git_commit: # optional
    # Ignore existing releases if present in Octopus Deploy with the matching version number.
    ignore_existing: # optional
    # The release notes text associated with the new release (Markdown is supported).
    release_notes: # optional
    # A file containing the release notes associated with the new release (Markdown is supported). Use either `release_notes` or this input, supplying both is not supported.
    release_notes_file: # optional
    # The instance URL hosting Octopus Deploy (i.e. "https://octopus.example.com/"). The instance URL is required, but you may also use the OCTOPUS_URL environment variable.
    server: # optional
    # The API key used to access Octopus Deploy. An API key is required, but you may also use the OCTOPUS_API_KEY environment variable. It is strongly recommended that this value retrieved from a GitHub secret.
    api_key: # optional
    # The name of a space within which this command will be executed. The space name is required, but you may also use the OCTOPUS_SPACE environment variable.
    space: # optional


    - name: Docker Run Action msp-in
  # You may pin to the exact commit or the version.
  # uses: msp-in/docker-run-action@20dd353e1d8b17b66d3e215694abc3e18938b478
  uses: msp-in/docker-run-action@v1.2
  with:
    # Image
    image: 
    # Options
    options: # optional
    # Run command in container
    run: # optional
    # Use a specific shell
    shell: # optional, default is sh
    # Registry
    registry: # optional
    # Username
    username: # optional
    # Password
    password: # optional
    # Docker Network ID
    docker_network: # optional, default is ${{ job.container.network }}


    - name: Run Runbook in Octopus Deploy
  # You may pin to the exact commit or the version.
  # uses: OctopusDeploy/run-runbook-action@c35c25d435fae32d3b77484ca49352e815adf8d3
  uses: OctopusDeploy/run-runbook-action@v3.0.3
  with:
    # The name of the project associated with this runbook.
    project: 
    # The name of the runbook.
    runbook: 
    # A multi-line list of environments to deploy to.
    environments: 
    # A multi-line list of tenant names to deploy to.
    tenants: # optional
    # A multi-line list of tenant tags (canonical names) to use to locate tenants to deploy to.
    tenant_tags: # optional
    # Whether to use guided failure mode if errors occur during the deployment.
    use_guided_failure: # optional
    # A multi-line list of prompted variable values. Format: name:value
    variables: # optional
    # The instance URL hosting Octopus Deploy (i.e. "https://octopus.example.com/"). The instance URL is required, but you may also use the OCTOPUS_URL environment variable.
    server: # optional
    # The API key used to access Octopus Deploy. An API key is required, but you may also use the OCTOPUS_API_KEY environment variable. It is strongly recommended that this value retrieved from a GitHub secret.
    api_key: # optional
    # The name of a space within which this command will be executed. The space name is required, but you may also use the OCTOPUS_SPACE environment variable.
    space: # optional


    - name: file-description-auto-generator
  # You may pin to the exact commit or the version.
  # uses: mx-in/file-description-auto-generator@24deadc8789c5a7b30e46d0d4970f94e0a681315
  uses: mx-in/file-description-auto-generator@v0.1-alpha.1
  with:
    # Your openai api key
    openai-api-key: 
    # The OpenAI prompt
    openai-prompt: # optional
    # The model to use
    model: # optional, default is text-davinci-003
    # Source file and dist out put files
    source-dist-map: # optional

    - name: SecureStack All-In-One GitHub Action
  # You may pin to the exact commit or the version.
  # uses: SecureStackCo/actions-all-in-one@96dc79a3c4081a8333040c6bf84b0c528ccb1eb9
  uses: SecureStackCo/actions-all-in-one@v0.1.2
  with:
    # SecureStack API key - generate an API key at https://app.securestack.com
    securestack_api_key: 
    # SecureStack Application ID - can be retrieved by accessing required application at https://app.securestack.com
    securestack_app_id: 
    # Severities lower than this value will be reported in the workflow console but will not cause an error for the action; value should be one of: critical | high | medium | low
    severity: 

    - name: Run in MozillaBuild
  # You may pin to the exact commit or the version.
  # uses: dothq/mozillabuild-shell-action@68ae04d9e59e90c3f00d87d4ca0263a2e15bf2cd
  uses: dothq/mozillabuild-shell-action@1.0.0
  with:
    # Command or script you want to execute
    run: # default is echo "Change the run input to any command or script."
- name: Hugo in Action
  # You may pin to the exact commit or the version.
  # uses: wxdlong/hugo-action@4fc198b8478b56364e5cc678dd86e4cbd36b838f
  uses: wxdlong/hugo-action@v2
  with:
    # Github access token,
    access_token: 
    # Which branch will publish. Default value is gh-pages for unit|organization, If for personal set value to master
    branch: # optional, default is gh-pages
    # Github page cname. eg: https://ycat.top
    cname: # optional, default is 
    
    - name: Setup Swift in Windows
  # You may pin to the exact commit or the version.
  # uses: rinsuki/setup-swift-windows@44bd65fd99826e236033ad7f90967f22f278dcaa
  uses: rinsuki/setup-swift-windows@0.1.1
  with:
    # Version of Swift (e.g. `5.4.2`)
    version: 

    - name: Version In File Updater
  # You may pin to the exact commit or the version.
  # uses: bhaumikmistry/Version-update-action@6bb7a1a71054f9e79802707c74bc1363d09a7196
  uses: bhaumikmistry/Version-update-action@v0.2.1-alpha
  with:
    # version file name to use
    versionFileName: # optional, default is version.md
    # Version number is saved between, for e.g "0.0.0"
    versionNumberEncapsulateText: # optional, default is "

    - name: Compile Mermaid in Markdown
  # You may pin to the exact commit or the version.
  # uses: divvun/compile-mermaid-markdown-action@889f201a2fad0fb40d2e5f9f8b85c4b8ad07c1a1
  uses: divvun/compile-mermaid-markdown-action@v1.0.0
  with:
    # the path to the files to compile
    files: 
    # Where to output the file - std otherwise
    output: 

    - name: Compile Mermaid in Markdown
  # You may pin to the exact commit or the version.
  # uses: divvun/compile-mermaid-markdown-action@889f201a2fad0fb40d2e5f9f8b85c4b8ad07c1a1
  uses: divvun/compile-mermaid-markdown-action@v1.0.0
  with:
    # the path to the files to compile
    files: 
    # Where to output the file - std otherwise
    output: 
    - name: Jira-issue-in-description
  # You may pin to the exact commit or the version.
  # uses: BoscoDomingo/jira-issue-in-description-action@d43c6c76e86dd8d13c21f0bb8a4638e493445d1c
  uses: BoscoDomingo/jira-issue-in-description-action@v1.1.1
  with:
    # Token used to update PR description and add labels. Can be passed in using `{{ secrets.GITHUB_TOKEN }}`
    github-token: 
    # API Token used to access the JIRA REST API. Must have read access to your JIRA Projects & Issues. Format: `<jira email>:<jira token>`
    jira-token: 
    # The subdomain of JIRA cloud that you use to access it. Ex: "https://your-domain.atlassian.net"
    jira-base-url: 
    # Where to look for issue key: branch | pr-title | both
    use: # optional
    # A regex to ignore running on certain branches, like production etc.
    skip-branches: # optional, default is 
    # Key of project in jira. First part of issue key
    jira-project-key: # optional, default is 
    #  Custom regexp to extract issue number from branch name.
    custom-issue-number-regexp: # optional, default is 
    #  Mark the PR status check as failed when a jira issue is not found
    fail-when-jira-issue-not-found: # optional, default is false

    - name: Get GKE Credentials
  # You may pin to the exact commit or the version.
  # uses: google-github-actions/get-gke-credentials@35ab0d2b2d48792c19f09325413bd185c8d44394
  uses: google-github-actions/get-gke-credentials@v1.0.2
  with:
    # Name of the cluster for which to get credentials. If specified as a full
resource name (e.g. "projects/p/locations/l/clusters/c"), then then
"project_id" and "location" inputs are optional. If only specified as the
name (e.g. "my-cluster"), then the "project_id" and "location" inputs may
be required.
    cluster_name: 
    # Location (e.g. region or zone) in which the cluster resides. This value is
required unless you specify "cluster_name" as a full resource name.
    location: # optional
    # Project ID where the cluster is deployed. If provided, this will override
the project configured by previous steps or environment variables. If not
provided, the project will be inferred, best-effort.
    project_id: # optional
    # If true, use the Google Cloud auth plugin in kubectl instead of a
short-lived access token. The default value is false.
    use_auth_provider: # optional
    # If true, use the internal IP address for the cluster endpoint. This is
mostly used with private GKE clusters. The default value is false.
    use_internal_ip: # optional
    # Name to use when creating the kubectl context. If not specified, the
default value is "gke_{PROJECT_ID}_{LOCATION}_${CLUSTER_NAME}".
    context_name: # optional
    # If true, uses the Connect Gateway endpoint to connect to cluster. For
more details https://cloud.google.com/anthos/multicluster-management/gateway.
The default value is false.
    use_connect_gateway: # optional
    # Fleet membership name of form "projects/PROJECT_ID/locations/LOCATION/memberships/MEMBERSHIP_NAME"
to use for generating Connect Gateway endpoint. This only applies if "use_connect_gateway" is true.
Defaults to auto discovery if empty.
    fleet_membership_name: # optional
    # Project ID from which to pull quota. The caller must have
serviceusage.services.use permission on the project. If unspecified, this
defaults to the project of the authenticated principle. This is an
advanced setting, most users should leave this blank.
    quota_project_id: # optional


    - name: Get Secret Manager secrets
  # You may pin to the exact commit or the version.
  # uses: google-github-actions/get-secretmanager-secrets@4d6d3dfd94110800dda8d84109cb6da0f6a5919d
  uses: google-github-actions/get-secretmanager-secrets@v1.0.1
  with:
    # Comma-separated or newline-separated list of secrets to fetch. Secrets
must be of the format <project>/<secret> or <project>/<secret>/<version>.
    secrets: 
    # Minimum line length for a secret to be masked. Extremely short secrets
(e.g. "{" or "a") can make GitHub Actions log output unreadable. This is
especially important for multi-line secrets, since each line of the secret
is masked independently.
    min_mask_length: # optional, default is 4
    - name: SBOM-generator-action
  # You may pin to the exact commit or the version.
  # uses: advanced-security/sbom-generator-action@375dee8e6144d9fd0ec1f5667b4f6fb4faacefed
  uses: advanced-security/sbom-generator-action@v0.0.1
  - name: GetPackagePP
  # You may pin to the exact commit or the version.
  # uses: DiscordPP/getpackagepp@6ca7875dcc981e670e5c7231ae25aa6c50e71073
  uses: DiscordPP/getpackagepp@1.1
  with:
    # Space-separated list of packages to install using apt.  Will
only run on Ubuntu.

    apt: # optional
    # Space-separated list of packages to install using apt-get.  Will
only run on Ubuntu.

    apt-get: # optional
    # Space-separated list of packages to install using brew install.  Will
only run on macOS.

    brew: # optional
    # Space-separated list of packages to install using vcpkg install.  Will
only run on Windows.

    vcpkg: # optional

    - name: Speakeasy Client SDK Generation Action
  # You may pin to the exact commit or the version.
  # uses: speakeasy-api/sdk-generation-action@7d6e7bf970b0152adcbfe083ae6dafee9b561a62
  uses: speakeasy-api/sdk-generation-action@v14.26
  with:
    # The version of the Speakeasy CLI to use or "latest"
    speakeasy_version: # optional, default is latest
    # The location of the OpenAPI document to use, either a relative path within the repo or a URL to a publicly hosted document
    openapi_doc_location: # optional
    # The auth header to use when fetching the OpenAPI document if it is not publicly hosted. For example `Authorization`.
If using a private speakeasy hosted document use `x-api-key`. This header will be populated with the openapi_doc_auth_token provided.
    openapi_doc_auth_header: # optional
    # The auth token to use when fetching the OpenAPI document if it is not publicly hosted. For example `Bearer <token>` or `<token>`.
    openapi_doc_auth_token: # optional
    # A yaml string containing a list of OpenAPI documents to use, if multiple documents are provided they will be merged together, prior to generation.

If the document lives within the repo a relative path can be provided, if the document is hosted publicly a URL can be provided.

If the documents are hosted privately a URL can be provided along with the `openapi_doc_auth_header` and `openapi_doc_auth_token` inputs.
Each document will be fetched using the provided auth header and token, so they need to be valid for all documents.

For example:
openapi_docs: |
  - https://example.com/openapi1.json
  - https://example.com/openapi2.json
    openapi_docs: # optional
    # The path to output the modified OpenAPI spec
    openapi_doc_output: # optional, default is ./openapi.yaml
    # A GitHub access token with write access to the repo
    github_access_token: 
    # A yaml string containing a list of languages to generate SDKs for example:
languages: |
  - go: ./go-sdk # specifying a output directory
  - python # using default output of ./python-client-sdk
  - typescript # using default output of ./typescript-client-sdk
  - java # using default output of ./java-client-sdk
  - php # using default output of ./php-client-sdk
  - ruby # using default output of ./ruby-client-sdk

If multiple languages are present we will treat this repo as a mono repo, if a single language is present as a single language repo and generate the sdk
in the root of the repo if not path is provided.
    languages: 
    # Create a Github release on generation
    create_release: # optional, default is true
    # Whether the Python SDK will be published to PyPi
    publish_python: # optional, default is false
    # Whether the Typescript SDK will be published to NPM
    publish_typescript: # optional, default is false
    # Whether the Terraform Provider will be published to the Terraform Registry
    publish_terraform: # optional, default is false
    # Whether the PHP SDK will be published to Packagist this will also create a release on Github
    publish_php: # optional, default is false
    # Whether the Ruby SDK will be published to Rubygems
    publish_ruby: # optional, default is false
    # Whether the Java SDK will be published to the provided OSSRH URL
    publish_java: # optional, default is false
    # Whether the C# SDK will be published to Nuget
    publish_csharp: # optional, default is false
    # The Speakeasy API key to authenticate the Speakeasy CLI with
    speakeasy_api_key: 
    # Force the SDK to be regenerated
    force: # optional, default is false
    # The maximum number of suggestions to apply when using the 'suggest' action step.
    max_suggestions: # optional, default is 5
    # The mode to run the workflow in when using the 'generate' action, valid options are 'direct' or 'pr', defaults to 'direct'.
This is intended to be used along with the `action` input to determine the current action step to run.
  - 'direct' mode will generally create a branch to generate the SDK on then merge this directly to the branch the workflow is configure to run on (normally 'main' or 'master') after compilation is successful.
  - 'pr' will create a branch to generate the SDK on then create a pull request to merge this branch to the branch the workflow is configure to run on (normally 'main' or 'master') after compilation is successful.
See documentation for more details.
    mode: # optional, default is direct
    # The current action step to run, valid options are 'validate', 'generate', 'suggest', 'finalize', 'finalize-suggestion', or 'release', defaults to 'generate'.
This is intended to be used along with the `mode` input to determine the current action step to run.
  - 'validate' will validate the OpenAPI document and return addressable warnings and errors.
  - 'generate' will generate the SDK and commit the changes to the branch.
  - 'suggest' will apply suggestions to the OpenAPI document and commit the changes to the branch.
  - 'finalize' depending on mode will either merge the branch to the branch the workflow is configure to run on (normally 'main' or 'master') or create a pull request.
  - 'finalize-suggestion' will create a pull request with the suggestions from the LLM model.
  - 'release' will create a release on Github.
    action: # optional
    # The name of the branch to finalize, only used for the 'finalize' action step.
    branch_name: # optional
    # Output of `speakeasy suggest` CLI command, only used for the 'finalize-suggestion' action step.
    cli_output: # optional
    # The version of the previous generation, only used for the 'finalize' action step.
    previous_gen_version: # optional
    # Internal use only
    output_tests: # optional
    # Internal use only
    speakeasy_server_url: # optional
    # The OpenAI API key to authenticate to access LLM suggestions. If left empty it will use Speakeasy's key within platform limits.
    openai_api_key: # optional
    # The working directory for running Speakeasy CLI commands in the action
    working_directory: # optional

    - name: Setup Go environment
  uses: actions/setup-go@v4.1.0
  with:
    # The Go version to download (if necessary) and use. Supports semver spec and ranges. Be sure to enclose this option in single quotation marks.
    go-version: # optional
    # Path to the go.mod or go.work file.
    go-version-file: # optional
    # Set this option to true if you want the action to always check for the latest available version that satisfies the version spec
    check-latest: # optional
    # Used to pull Go distributions from go-versions. Since there's a default, this is typically not supplied by the user. When running this action on github.com, the default value is sufficient. When running on GHES, you can pass a personal access token for github.com if you are experiencing rate limiting.
    token: # optional, default is ${{ github.server_url == 'https://github.com' && github.token || '' }}
    # Used to specify whether caching is needed. Set to true, if you'd like to enable caching.
    cache: # optional, default is true
    # Used to specify the path to a dependency file - go.sum
    cache-dependency-path: # optional
    # Target architecture for Go to use. Examples: x86, x64. Will use system architecture by default.
    architecture: # optional

    - name: Cache
  uses: actions/cache@v1.2.1
  with:
    # A directory to store and save the cache
    path: 
    # An explicit key for restoring and saving the cache
    key: 
    # An ordered list of keys to use for restoring the cache if no cache hit occurred for key
    restore-keys: # optional
    - name: Dapr tool installer
  # You may pin to the exact commit or the version.
  # uses: dapr/setup-dapr@ffde132592c51fcb876dff3925598fd150137569
  uses: dapr/setup-dapr@v1
  with:
    # Version of Dapr CLI to install
    version: # optional, default is 1.2.0

    - name: Deploy Docker to Azure VM
  # You may pin to the exact commit or the version.
  # uses: bitovi/github-actions-docker-to-azure-vm@0a044e4e9c35096c7b8b6cb926fdd25c64cab067
  uses: bitovi/github-actions-docker-to-azure-vm@v1.0.1
  with:
    # Azure client ID
    AZURE_ARM_CLIENT_ID: 
    # Azure client secret
    AZURE_ARM_CLIENT_SECRET: 
    # Azure subscription ID
    AZURE_ARM_SUBSCRIPTION_ID: 
    # Azure tenant ID
    AZURE_ARM_TENANT_ID: 
    # Azure default region
    AZURE_DEFAULT_REGION: # default is eastus
    # Azure storage account name
    AZURE_STORAGE_ACCOUNT: # default is bitops
    # Azure storage account SKU
    AZURE_STORAGE_SKU: # default is Standard_LRS
    # Backend Bucket to use for Terraform state. Defaults to `${org}-${repo}-{branch}-tf-state`
    tf_state_bucket: 
    # Force purge and deletion of bucket on destroy. Any file contained there will be destroyed. `stack_destroy` must also be `true`
    tf_state_bucket_destroy: # optional, default is true
    # Set to override the Azure resource identifier for the deployment.  Defaults to `${org}-{repo}-{branch}`.  Use with destroy to destroy specific resources.
    azure_resource_identifier: 
    # Set to override the Azure VM username for the deployment.  Defaults to `ubuntu`.
    azure_vm_admin_username: # default is ubuntu
    # Set to override the Azure VM password for the deployment.  Defaults to `insecurePasswordABC123@`. Prefer GH Secrets.
    azure_vm_admin_password: # default is insecurePasswordABC123@
    # Set to true to run docker-compose down and docker system prune --all --force --volumes after.
    docker_full_cleanup: # optional
    # Relative path for the directory of the app (i.e. where `Dockerfile` and `docker-compose.yaml` files are located). This is the directory that is copied to the EC2 instance.  Default is the root of the repo. Add a .gha-ignore file with a list of files to be exluded.
    app_directory: # optional
    # Will generate a timestamped compressed file and delete the app repo directory.
    app_directory_cleanup: # optional
    # Port to expose for the app
    app_port: # optional
    # Load balancer listening port. Defaults to 80 if NO FQDN provided, 443 if FQDN provided
    lb_port: # optional
    # Load balancer health check string. Defaults to HTTP:app_port
    lb_healthcheck: # optional
    # Set to "true" to Destroy the stack. Will delete the elb_logs bucket after the destroy action runs.
    stack_destroy: # optional, default is false
    # Define the root domain name for the application. e.g. app.com
    domain_name: # optional
    # Define the sub-domain part of the URL. Defaults to `${org}-${repo}-{branch}`
    sub_domain: # optional
    # Deploy to root domain. Will generate two DNS recrods, one for root, another for www
    root_domain: # optional
    # Define the certificate ARN to use for the application
    cert_arn: # optional
    # Generates and manage the root cert for the application
    create_root_cert: # optional
    # Generates and manage the sub-domain certificate for the application
    create_sub_cert: # optional
    # Makes the application not to use a certificate by disabling certificate lookup.
    no_cert: # optional
    # A list of targets to create before the full stack creation. Example: `
    targets: # optional
    # A JSON object of additional tags that will be included on created resources. Example: `{"key1": "value1", "key2": "value2"}`
    additional_tags: # optional
    # Directory path in application env to mount directory, default is `data`
    application_mount_target: # optional, default is data
    # Directory path within docker env to mount directory to, default is `/data`
    data_mount_target: # optional
    # Set to "true" to enable debug mode
    DEBUG_MODE: # optional, default is false
    # Set to override the BitOps image to use for the deployment.  Defaults to `bitovi/bitops:latest`.
    BITOPS_IMAGE: # optional, default is bitovi/bitops:latest
    
    - name: Vercel Snaplet Deployments
  # You may pin to the exact commit or the version.
  # uses: snaplet/vercel-preview-database-action@3a1bef8c9ac9f69e5c472833e830166273661b7f
  uses: snaplet/vercel-preview-database-action@v1.0.1
  with:
    # Delete the preview on vercel and the instant database related to it
    delete: # optional, default is ${{ github.event.action == 'closed' }}
    # Await for the deployment to be ready and output the deployment URL
    vercel-await-for-deployment: # optional
    # The environment variable name to set the preview database deployment URL
    vercel-env: # optional, default is DATABASE_URL
    # Command set for the Ignored Build Step in your project settings, the default script is canceling every preview deployments coming from the Vercel GitHub App.
    vercel-ignored-build-command: # optional, default is curl -sS "https://raw.githubusercontent.com/snaplet/vercel-action/v3/scripts/ignore-build.mjs" | node --input-type=module
    # Command used to generate the instant database
    database-create-command: # optional, default is snaplet preview-database create --git --latest
    # Command used to delete the instant database
    database-delete-command: # optional, default is snaplet preview-database drop --git
    # Command used to get the instant database url
    database-url-command: # optional, default is snaplet preview-database url --git
    # Reset the database state on each commit
    database-reset: # optional
    - name: Deploy Single VM Stackstorm to AWS EC2
  # You may pin to the exact commit or the version.
  # uses: bitovi/github-actions-deploy-stackstorm@d46c4353621423c6e704ba613696fc8d822058a7
  uses: bitovi/github-actions-deploy-stackstorm@v0.3.0
  with:
    # Specifies if this action should checkout the code
    checkout: # optional, default is true
    # AWS access key ID
    aws_access_key_id: 
    # AWS secret access key
    aws_secret_access_key: 
    # AWS session token, if you're using temporary credentials
    aws_session_token: # optional
    # AWS default region
    aws_default_region: # default is us-east-1
    # The AWS EC2 instance type
    aws_ec2_instance_type: # optional, default is t2.medium
    # The AWS IAM instance profile to use for the EC2 instance. Use if you want to pass an AWS role with specific permissions granted to the instance
    aws_ec2_instance_profile: # optional
    # Auto-generated by default so it's unique for org/repo/branch. Set to override with custom naming the unique AWS resource identifier for the deployment. Defaults to `${org}-${repo}-${branch}`.
    aws_resource_identifier: # optional
    # Bool, whether an AWS VPC should be created in the action. Otherwise, the existing default VPC will be used.
    aws_create_vpc: # optional, default is false
    # A list of additional tags that will be included on created resources. Example: `{"key1": "value1", "key2": "value2"}`
    aws_extra_tags: # optional, default is {}
    # Set to true to provision infrastructure (with Terraform) but skip the app deployment (with ansible)
    infrastructure_only: # optional, default is false
    # AWS S3 bucket to use for Terraform state. Defaults to `${org}-${repo}-${branch}-tf-state`
    tf_state_bucket: # optional
    # Username used by StackStorm standalone authentication. Set as a secret in GH Actions.
    st2_auth_username: 
    # Password used by StackStorm standalone authentication. Set as a secret in GH Actions.
    st2_auth_password: 
    # Comma separated list of packs to install. If you modify this option, be sure to also include `st2` in the list.
    st2_packs: # optional, default is st2
    # Relative path from project root to Ansible vars file. If you'd like to adjust more advanced configuration; st2 version, st2.conf, RBAC, chatops, auth, etc. See https://github.com/stackStorm/ansible-st2#variables for the full list of settings. The Ansible vars will take higher precedence over the GHA inputs.
    st2_ansible_extra_vars_file: # optional
    # Set to "true" to Destroy the created AWS infrastructure for this instance
    tf_stack_destroy: # optional, default is false
    # Force purge and deletion of tf_state_bucket defined. Any file contained there will be destroyed. tf_stack_destroy must also be true.
    tf_state_bucket_destroy: # optional, default is false
    # Define the root domain name for the application. e.g. bitovi.com. If empty, ELB URL will be provided.
    aws_domain_name: # optional
    # Define the sub-domain part of the URL. Defaults to `${org}-${repo}-{branch}`
    aws_sub_domain: # optional
    # Deploy application to root domain. Will create root and www DNS records. Domain must exist in Route53.
    aws_root_domain: # optional
    # Existing certificate ARN to be used in the ELB. Use if you manage a certificate outside of this action. See https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-list.html for how to find the certificate ARN.
    aws_cert_arn: # optional
    # Generates and manage the root certificate for the application to be used in the ELB.
    aws_create_root_cert: # optional
    # Generates and manage the sub-domain certificate for the application to be used in the ELB.
    aws_create_sub_cert: # optional
    # Set this to true if you want not to use a certificate in the ELB.
    aws_no_cert: # optional
    - name: setup-atmos
  # You may pin to the exact commit or the version.
  # uses: cloudposse/github-action-setup-atmos@b3349c9182acf83353941d93c33358a8636c1b24
  uses: cloudposse/github-action-setup-atmos@1.0.2
  with:
    # Version Spec of the version to use. Examples: 1.x, 10.15.1, >=10.15.0.
    atmos-version: # optional, default is latest
    # Flag to indicate if the wrapper script will be installed to wrap subsequent calls of the `atmos` binary and expose its STDOUT, STDERR, and exit code as outputs named `stdout`, `stderr`, and `exitcode` respectively. Defaults to `true`.
    install-wrapper: # optional, default is true
    # Used to pull node distributions from Cloud Posse's GitHub repository. Since there's a default, this is typically not supplied by the user. When running this action on github.com, the default value is sufficient. When running on GHES, you can pass a personal access token for github.com if you are experiencing rate limiting.
    token: # optional, default is ${{ github.server_url == 'https://github.com' && github.token || '' }}
    - name: StackQL Studios - Setup StackQL
  # You may pin to the exact commit or the version.
  # uses: stackql/setup-stackql@7de82feecdd229bedb876a83899b552428598d6f
  uses: stackql/setup-stackql@v1.2.0
  with:
    # Whether or not to install a wrapper to wrap subsequent calls of the `stackql` binary and expose its STDOUT, STDERR, and exit code as outputs named `stdout`, `stderr`, and `exitcode` respectively. Defaults to `true`.
    use_wrapper: # optional, default is false
    - name: Preview Environments
  # You may pin to the exact commit or the version.
  # uses: UffizziCloud/preview-action@6f946b7c6d38a24e28a134e6f833783dfaaaf782
  uses: UffizziCloud/preview-action@v2.6.1
  with:
    # An alternate compose file
    compose-file: # optional, default is docker-compose.yaml
    # URL to Uffizzi
    server: # default is https://app.uffizzi.com
    # Uffizzi username
    username: # optional
    # Uffizzi password
    password: # optional
    # Uffizzi project slug
    project: # optional
    # Username to authenticate to GHCR
    ghcr-username: # optional
    # Password to authenticate to GHCR
    ghcr-access-token: # optional
    # Value of `github.event.number` context
    github-event-number: # optional
    # Value of `github.ref` context
    github-ref: # optional
    # Value of `github.repository` context
    github-repository: # optional
    # 
    request-token: # optional
    # 
    request-token-url: # optional
    # 
    dockerhub-username: # optional
    # 
    dockerhub-password: # optional
    # Azure username
    acr-username: # optional
    # Azure password
    acr-password: # optional
    # Azure registry url
    acr-registry-url: # optional
    # Amazon Web Services access key id
    aws-access-key-id: # optional
    # Amazon Web Services secret access key
    aws-secret-access-key: # optional
    # Amazon Web Services registry url
    aws-registry-url: # optional
    # Google Cloud service key
    gcloud-service-key: # optional
    # Custom docker registry username
    docker-registry-username: # optional
    # Custom docker registry password
    docker-registry-password: # optional
    # Custom docker registry url
    docker-registry-url: # optional
    - name: Custom Models Action
  # You may pin to the exact commit or the version.
  # uses: datarobot-oss/custom-models-action@0a5d55659824973261d6b49389569dd4e28795bf
  uses: datarobot-oss/custom-models-action@v1.6.0
  with:
    # DataRobot authentication API token.
    api-token: 
    # DataRobot frontend web server.
    webserver: 
    # The branch for which pull request and push events will trigger the action.
    branch: 
    # Determines the namespace under which models and deployments will be created, updated and
deleted.

    namespace: # optional
    # Whether to detected local deleted model definitions and consequently delete them
in DataRobot.

    allow-model-deletion: # optional, default is false
    # Whether to detect local deleted deployment definitions and consequently delete them
in DataRobot.

    allow-deployment-deletion: # optional, default is false
    # Whether to handle custom inference models only, without deployments..

    models-only: # optional, default is false
    # Whether a request to an HTTPS URL will be made without a certificate verification.

    skip-cert-verification: # optional, default is false
    
    
    
